{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99786a37",
   "metadata": {},
   "source": [
    "# Async IO in Python: A Complete Walkthrough\n",
    "\n",
    "Async IO is a concurrent programming design that has received dedicated support in Python, evolving rapidly from Python 3.4 through 3.7, and probably beyond.\n",
    "\n",
    "<https://realpython.com/async-io-python/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89ce8c2b",
   "metadata": {},
   "source": [
    "## 001. Synchronous Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb605f4",
   "metadata": {},
   "source": [
    "**Parallelism** consists of performing multiple operations at the same time. **Multiprocessing** is a means to effect parallelism, and it entails spreading tasks over a computer’s central processing units (CPUs, or cores). Multiprocessing is well-suited for CPU-bound tasks: tightly bound for loops and mathematical computations usually fall into this category.\n",
    "\n",
    "**Concurrency** is a slightly broader term than parallelism. It suggests that multiple tasks have the ability to run in an overlapping manner. (There’s a saying that concurrency does not imply parallelism.)\n",
    "\n",
    "**Threading** is a concurrent execution model whereby multiple threads take turns executing tasks. One process can contain multiple threads. Python has a complicated relationship with threading thanks to its GIL, but that’s beyond the scope of this article.\n",
    "\n",
    "async IO is a single-threaded, single-process design: it uses **cooperative multitasking**. It has been said in other words that async IO gives a feeling of concurrency despite using a single thread in a single process. Coroutines (a central feature of async IO) can be scheduled concurrently, but they are not inherently concurrent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ca7850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad49b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q faker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b212460",
   "metadata": {},
   "source": [
    "### 002.001 The async/await Syntax and Native Coroutines\n",
    "\n",
    "Let’s take the immersive approach and write some async IO code. This short program is the Hello World of async IO but goes a long way towards illustrating its core functionality:\n",
    "\n",
    "1. Create a function `count_sync`\n",
    "    1. after printing, it waits synchronously 1 sec, then prints two\n",
    "1. Create a function `main_sync`\n",
    "    1. it runs `count_sync` in sequence 3 times\n",
    "1. Create a function `count_async`\n",
    "    1. after printing, it waits asynchronously 1 sec, then prints two\n",
    "1. Create a function `main_async`\n",
    "    1. it runs `count_async` asynchronously 3 times\n",
    "1. The output should be One Two One ... for the sync version, taking 3 s. And One One ... for the async one, taking sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c741ca30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Sync\n",
      "Two Sync\n",
      "One Sync\n",
      "Two Sync\n",
      "One Sync\n",
      "Two Sync\n",
      "sync version executed in 3.02 seconds.\n",
      "One Async\n",
      "One Async\n",
      "One Async\n",
      "Two Async\n",
      "Two Async\n",
      "Two Async\n",
      "async version executed in 1.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "1\n",
    "# def count_sync():\n",
    "#     print(\"One Sync\")\n",
    "#     ...\n",
    "#     print(\"two sync\")\n",
    "\n",
    "2\n",
    "# def main_sync():\n",
    "#     ...\n",
    "\n",
    "3\n",
    "# async def count_async():\n",
    "#     print(\"One Async\")\n",
    "#     ...\n",
    "#     print(\"two async\")\n",
    "\n",
    "\n",
    "4\n",
    "# async def main_async():\n",
    "#     ...\n",
    "\n",
    "5\n",
    "# s = time.perf_counter()\n",
    "# main_sync()\n",
    "# elapsed = time.perf_counter() - s\n",
    "# print(f\"sync version executed in {elapsed:0.2f} seconds.\")\n",
    "\n",
    "# s = time.perf_counter()\n",
    "# asyncio.run(main_async())\n",
    "# elapsed = time.perf_counter() - s\n",
    "# print(f\"async version executed in {elapsed:0.2f} seconds.\")\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "1\n",
    "def count_sync():\n",
    "    print(\"One Sync\")\n",
    "    time.sleep(1)\n",
    "    print(\"Two Sync\")\n",
    "\n",
    "2\n",
    "def main_sync():\n",
    "    for _ in range(3):\n",
    "        count_sync()\n",
    "\n",
    "3\n",
    "async def count_async():\n",
    "    print(\"One Async\")\n",
    "    await asyncio.sleep(1)\n",
    "    print(\"Two Async\")\n",
    "\n",
    "4\n",
    "async def main_async():\n",
    "    await asyncio.gather(count_async(), count_async(), count_async())\n",
    "\n",
    "5\n",
    "s = time.perf_counter()\n",
    "main_sync()\n",
    "elapsed = time.perf_counter() - s\n",
    "print(f\"sync version executed in {elapsed:0.2f} seconds.\")\n",
    "\n",
    "s = time.perf_counter()\n",
    "asyncio.run(main_async())\n",
    "elapsed = time.perf_counter() - s\n",
    "print(f\"async version executed in {elapsed:0.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce0b85",
   "metadata": {},
   "source": [
    "### 002.002 The Rules of Async IO\n",
    "\n",
    "Here’s one example of how async IO cuts down on wait time: given a coroutine makerandom() that keeps producing random integers in the range [0, 10], until one of them exceeds a threshold, you want to let multiple calls of this coroutine not need to wait for each other to complete in succession. You can largely follow the patterns from the two scripts above, with slight changes\n",
    "\n",
    "1. `makerandom` \n",
    "    1. should keep generating `i` until one it's greater than threshold.\n",
    "    1. if it isn't, it should print f\"{i} too low; retrying.\",\n",
    "    1. then sleep asynchronously for `i + 1` seconds, \n",
    "    1. the generate a new one\n",
    "1. `main`\n",
    "    1. should run 3 makerandom with idx in range 0 to 2 asynchronously\n",
    "1. should gather the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4db5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mInitiated makerandom(idx=0, threshold=9).\n",
      "\u001b[36m4 too low; retrying.\n",
      "\u001b[91mInitiated makerandom(idx=1, threshold=8).\n",
      "\u001b[91m4 too low; retrying.\n",
      "\u001b[35mInitiated makerandom(idx=2, threshold=7).\n",
      "\u001b[35m0 too low; retrying.\n",
      "\u001b[35m4 too low; retrying.\n",
      "\u001b[36m7 too low; retrying.\n",
      "\u001b[91m4 too low; retrying.\n",
      "\u001b[35m4 too low; retrying.\n",
      "\u001b[91m8 too low; retrying.\n",
      "\u001b[35m---> Finished: makerandom(2) == 10\u001b[0m\n",
      "\u001b[36m7 too low; retrying.\n",
      "\u001b[91m8 too low; retrying.\n",
      "\u001b[36m4 too low; retrying.\n",
      "\u001b[36m7 too low; retrying.\n",
      "\u001b[91m1 too low; retrying.\n",
      "\u001b[91m6 too low; retrying.\n",
      "\u001b[36m9 too low; retrying.\n",
      "\u001b[91m3 too low; retrying.\n",
      "\u001b[91m---> Finished: makerandom(1) == 9\u001b[0m\n",
      "\u001b[36m7 too low; retrying.\n",
      "\u001b[36m---> Finished: makerandom(0) == 10\u001b[0m\n",
      "\n",
      "r1: 10, r2: 9, r3: 10\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "# ANSI colors\n",
    "c = (\n",
    "    \"\\033[0m\",   # End of color\n",
    "    \"\\033[36m\",  # Cyan\n",
    "    \"\\033[91m\",  # Red\n",
    "    \"\\033[35m\",  # Magenta\n",
    ")\n",
    "\n",
    "# f\"{i} too low; retrying.\"\n",
    "\n",
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "OFFSET = 8\n",
    "\n",
    "1\n",
    "# async def makerandom(idx: int, threshold: int = 6) -> int:\n",
    "#     threshold = OFFSET - idx - 1\n",
    "#     print(c[idx + 1] + f\"Initiated makerandom({idx=}, {threshold=}).\" + c[0])\n",
    "#     i = random.randint(0, OFFSET)\n",
    "#     ...\n",
    "#     print(c[idx + 1] + f\"---> Finished: makerandom({idx}) == {i}\" + c[0])\n",
    "#     return i\n",
    "\n",
    "2\n",
    "# async def main():\n",
    "#     ..\n",
    "#     return res\n",
    "\n",
    "3\n",
    "# random.seed(444)\n",
    "# r1, r2, r3 = asyncio.run(main())\n",
    "# print(f\"r1: {r1}, r2: {r2}, r3: {r3}\")\n",
    "\n",
    "# solution\n",
    "\n",
    "async def makerandom(idx: int) -> int:\n",
    "    threshold = OFFSET - idx - 1\n",
    "    print(c[idx + 1] + f\"Initiated makerandom({idx=}, {threshold=}).\")\n",
    "    i = random.randint(0, OFFSET)\n",
    "    while i <= threshold:\n",
    "        print(c[idx + 1] + f\"{i} too low; retrying.\")\n",
    "        await asyncio.sleep(i + 1)\n",
    "        i = random.randint(0, OFFSET)\n",
    "    print(c[idx + 1] + f\"---> Finished: makerandom({idx}) == {i}\" + c[0])\n",
    "    return i\n",
    "\n",
    "async def main():\n",
    "    res = await asyncio.gather(*(makerandom(i) for i in range(3)))\n",
    "    return res\n",
    "\n",
    "random.seed(444)\n",
    "r1, r2, r3 = asyncio.run(main())\n",
    "print()\n",
    "print(f\"r1: {r1}, r2: {r2}, r3: {r3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139bfb11",
   "metadata": {},
   "source": [
    "### 002.003 Chaining Coroutines\n",
    "\n",
    "A key feature of coroutines is that they can be chained together. (Remember, a coroutine object is awaitable, so another coroutine can await it.) This allows you to break programs into smaller, manageable, recyclable coroutines:\n",
    "\n",
    "1. `load` \n",
    "    1. waits i secs, asynchronously\n",
    "    1. returns i\n",
    "1. `fire`\n",
    "    1. waits i secs, asynchronously\n",
    "    1. returns i plus the i from the following step as a tuple\n",
    "1. `chain`\n",
    "    1. runs load and puts result in `p1`\n",
    "    1. then feeds result to fire and puts result in `p2`\n",
    "1. `main`\n",
    "    1. initiates an instance of `chain` for each arg, concurrently\n",
    "1. finally\n",
    "    1. runs all the jobs in `main`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4b84ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cannon: (will take 8 seconds)\n",
      "loading laser: (will take 4 seconds)\n",
      "loading railgun: (will take 3 seconds)\n",
      "railgun loaded..\n",
      "firing railgun: (will take 8 seconds)\n",
      "laser loaded..\n",
      "firing laser: (will take 8 seconds)\n",
      "cannon loaded..\n",
      "firing cannon: (will take 0 seconds)\n",
      "cannon fired!\n",
      "--> Timing for cannon: total 8.00 seconds, partial (8, 0).\n",
      "railgun fired!\n",
      "--> Timing for railgun: total 11.00 seconds, partial (3, 8).\n",
      "laser fired!\n",
      "--> Timing for laser: total 12.00 seconds, partial (4, 8).\n",
      "Program finished in 12.01 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "1\n",
    "# async def load(n: str) -> int:\n",
    "#     i = random.randint(0, 10)\n",
    "#     print(f\"loading {n}: (will take {i} seconds)\")\n",
    "#     ...\n",
    "#     print(f\"{n} loaded..\")\n",
    "#     ...\n",
    "\n",
    "2\n",
    "# async def fire(n: str, last_i: int) -> tuple[int, int]:\n",
    "#     i = random.randint(0, 10)\n",
    "#     print(f\"firing {n}: (will take {i} seconds)\")\n",
    "#     ...\n",
    "#     print(f\"{n} fired!\")\n",
    "#     return (last_i, i)\n",
    "\n",
    "3\n",
    "# async def chain(n: str) -> None:\n",
    "#     start = time.perf_counter()\n",
    "#     ...\n",
    "#     ...\n",
    "#     end = time.perf_counter() - start\n",
    "#     print(f\"--> Timing for {n}: total {end:0.2f} seconds, partial {p2}.\")\n",
    "\n",
    "4\n",
    "# async def main(*args):\n",
    "#     ...\n",
    "\n",
    "5\n",
    "# random.seed(1672)\n",
    "# args = [\"cannon\", \"laser\", \"railgun\"]\n",
    "# start = time.perf_counter()\n",
    "# ...\n",
    "# end = time.perf_counter() - start\n",
    "# print(f\"Program finished in {end:0.2f} seconds.\")\n",
    "\n",
    "# solution\n",
    "\n",
    "async def load(n: str) -> int:\n",
    "    i = random.randint(0, 10)\n",
    "    print(f\"loading {n}: (will take {i} seconds)\")\n",
    "    await asyncio.sleep(i)\n",
    "    print(f\"{n} loaded..\")\n",
    "    return i\n",
    "\n",
    "async def fire(n: str, last_i: int) -> tuple[int, int]:\n",
    "    i = random.randint(0, 10)\n",
    "    print(f\"firing {n}: (will take {i} seconds)\")\n",
    "    await asyncio.sleep(i)\n",
    "    print(f\"{n} fired!\")\n",
    "    return (last_i, i)\n",
    "\n",
    "async def chain(n: str) -> None:\n",
    "    start = time.perf_counter()\n",
    "    p1 = await load(n)\n",
    "    p2 = await fire(n, p1)\n",
    "    end = time.perf_counter() - start\n",
    "    print(f\"--> Timing for {n}: total {end:0.2f} seconds, partial {p2}.\")\n",
    "\n",
    "async def main(*args):\n",
    "    await asyncio.gather(*(chain(n) for n in args))\n",
    "\n",
    "random.seed(1672)\n",
    "args = [\"cannon\", \"laser\", \"railgun\"]\n",
    "start = time.perf_counter()\n",
    "asyncio.run(main(*args))\n",
    "end = time.perf_counter() - start\n",
    "print(f\"Program finished in {end:0.2f} seconds.\")\n",
    "\n",
    "\n",
    "1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05aefde",
   "metadata": {},
   "source": [
    "### 002.004 Using a Queue\n",
    "\n",
    "There is an alternative structure that can also work with async IO: a number of producers, which are not associated with each other, add items to a queue. Each producer may add multiple items to the queue at staggered, random, unannounced times. A group of consumers pull items from the queue as they show up, greedily and without waiting for any other signal. One use-case for queues (as is the case here) is for the queue to act as a transmitter for producers and consumers that aren’t otherwise directly chained or associated with each other.\n",
    "\n",
    "\n",
    "1. `produce` pushes a random number of jobs to the queue\n",
    "    1. Use the itertools method that allows to returns a list of n somethings (in this case, None)\n",
    "    1. Add a tuple (an actual tuple) to the queue: first item is a random job, the other is a timestamp CAREFUL HERE, YOU ALWAYS MAKE SAME MISTAKE\n",
    "1. `consumer` gets the next available job and processes it\n",
    "    1. Q: we are using `while True`, isn't that going to cause problems?\n",
    "    1. Get the tuple off the queue\n",
    "    1. Tell the queue it can tick the job as complete\n",
    "1. `main` orchestrates the whole thing\n",
    "    1. create a queue\n",
    "    1. create and schedule a set with a task for each producer\n",
    "    1. make sure each of these tasks gets eventually garbage collected\n",
    "    1. do the same for consumer (use male names)\n",
    "    1. run all the producers tasks\n",
    "    1. Q: why only the producers?\n",
    "    1. wait until all jobs are processed\n",
    "    1. Q: how do we know we are done?\n",
    "    1. turn off the consumers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05780379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer Virginia added <Programmer, systems> to queue.\n",
      "    > Consumer Matthew got element <Programmer, systems> in 0.00047 seconds.\n",
      "Producer Margaret added <Energy manager> to queue.\n",
      "    > Consumer Jason got element <Energy manager> in 0.00092 seconds.\n",
      "Producer Virginia added <Clinical molecular geneticist> to queue.\n",
      "Producer Margaret added <Electrical engineer> to queue.\n",
      "    > Consumer Matthew got element <Clinical molecular geneticist> in 2.00042 seconds.\n",
      "    > Consumer Jason got element <Electrical engineer> in 1.00019 seconds.\n",
      "Producer Virginia added <Television floor manager> to queue.\n",
      "    > Consumer Matthew got element <Television floor manager> in 0.00126 seconds.\n",
      "Producer Margaret added <Civil engineer, contracting> to queue.\n",
      "    > Consumer Matthew got element <Civil engineer, contracting> in 0.00212 seconds.\n",
      "Producer Virginia added <Veterinary surgeon> to queue.\n",
      "    > Consumer Jason got element <Veterinary surgeon> in 0.00158 seconds.\n",
      "Producer Margaret added <Warden/ranger> to queue.\n",
      "    > Consumer Matthew got element <Warden/ranger> in 0.00064 seconds.\n",
      "Program completed in 30.01021 seconds.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import itertools as it\n",
    "import random\n",
    "import time\n",
    "\n",
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "NPROD = 3\n",
    "\n",
    "async def create_job(size: int = 5) -> str:\n",
    "    return fake.job()\n",
    "\n",
    "async def rand_sleep() -> None:\n",
    "    i = random.randint(0, 10)\n",
    "    await asyncio.sleep(i)\n",
    "\n",
    "1\n",
    "# async def produce(name: str, q: asyncio.Queue) -> None:\n",
    "#     n = random.randint(0, 10)\n",
    "#     for _ in ...\n",
    "#         await rand_sleep()\n",
    "#         i = await create_job()\n",
    "#         t = time.perf_counter()\n",
    "#         ...\n",
    "#         print(f\"Producer {name} added <{i}> to queue.\")\n",
    "\n",
    "2\n",
    "# async def consume(name: int, q: asyncio.Queue) -> None:\n",
    "#     while True:\n",
    "#         await rand_sleep()\n",
    "#         ...\n",
    "#         now = time.perf_counter()\n",
    "#         print(f\"    > Consumer {name} got element <{i}>\"\n",
    "#               f\" in {now-t:0.5f} seconds.\")\n",
    "#         ...\n",
    "\n",
    "3\n",
    "# async def main(nprod: int, ncon: int):\n",
    "#     q = ...\n",
    "#     producers = set()\n",
    "#     for _ in range(nprod):\n",
    "#         task = ...produce(fake.first_name_female(), q)\n",
    "#         producers.add(task)\n",
    "#         ...\n",
    "#     consumers = set()\n",
    "#     for _ in range(ncon):\n",
    "#         task = ...\n",
    "#         consumers.add(task)\n",
    "#         ...\n",
    "#     ...\n",
    "#     ...\n",
    "#     for c in consumers:\n",
    "#         ...\n",
    "\n",
    "\n",
    "# random.seed(444)\n",
    "# start = time.perf_counter()\n",
    "# asyncio.run(main(nprod=NPROD, ncon=2))\n",
    "# elapsed = time.perf_counter() - start\n",
    "# print(f\"Program completed in {elapsed:0.5f} seconds.\")\n",
    "\n",
    "\n",
    "# solution\n",
    "\n",
    "\n",
    "async def create_job(size: int = 5) -> str:\n",
    "    return fake.job()\n",
    "\n",
    "async def rand_sleep() -> None:\n",
    "    i = random.randint(0, 10)\n",
    "    await asyncio.sleep(i)\n",
    "\n",
    "1\n",
    "async def produce(name: int, q: asyncio.Queue) -> None:\n",
    "    n = random.randint(0, 10)\n",
    "    for _ in it.repeat(None, n):\n",
    "        await rand_sleep()\n",
    "        i = await create_job()\n",
    "        t = time.perf_counter()\n",
    "        await q.put((i, t))\n",
    "        print(f\"Producer {name} added <{i}> to queue.\")\n",
    "\n",
    "2\n",
    "async def consume(name: int, q: asyncio.Queue) -> None:\n",
    "    # A: This will have to be manually canceled below\n",
    "    while True:\n",
    "        await rand_sleep()\n",
    "        i, t = await q.get()\n",
    "        now = time.perf_counter()\n",
    "        print(f\"    > Consumer {name} got element <{i}>\"\n",
    "              f\" in {now-t:0.5f} seconds.\")\n",
    "        q.task_done()\n",
    "\n",
    "3\n",
    "async def main(nprod: int, ncon: int):\n",
    "    q = asyncio.Queue()\n",
    "    producers = set()\n",
    "    for _ in range(nprod):\n",
    "        task = asyncio.create_task(produce(fake.first_name_female(), q))\n",
    "        producers.add(task)\n",
    "        task.add_done_callback(producers.discard)\n",
    "    consumers = set()\n",
    "    for _ in range(ncon):\n",
    "        task = asyncio.create_task(consume(fake.first_name_male(), q))\n",
    "        consumers.add(task)\n",
    "        task.add_done_callback(consumers.discard)\n",
    "    # A: we know the producers have a finite number of actions to\n",
    "    # perform, and we want to wait for them to finish. The consumers, on\n",
    "    # the other hand are 'always on' (because of the while True) and we\n",
    "    # don't want to wait for them. We will manually switch them off when\n",
    "    # we are done.\n",
    "    await asyncio.gather(*producers)\n",
    "    # A: this tells us when we are done - there are no more tasks. Now\n",
    "    # we can switch them off.\n",
    "    await q.join()\n",
    "    for c in consumers:\n",
    "        c.cancel()\n",
    "\n",
    "\n",
    "random.seed(444)\n",
    "start = time.perf_counter()\n",
    "asyncio.run(main(nprod=NPROD, ncon=2))\n",
    "elapsed = time.perf_counter() - start\n",
    "print(f\"Program completed in {elapsed:0.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82df488",
   "metadata": {},
   "source": [
    "### 002.005 Async IO’s Roots in Generators\n",
    "\n",
    "The await keyword behaves similarly, marking a break point at which the coroutine suspends itself and lets other coroutines work. “Suspended,” in this case, means a coroutine that has temporarily ceded control but not totally exited or finished. Keep in mind that yield, and by extension yield from and await, mark a break point in a generator’s execution.\n",
    "\n",
    "1. `endless` is a generator that each time next is called on it returns one of 9,8,7,6,9...\n",
    "    1. Import the relevant package\n",
    "2. use `for ... in ` to print a few iterations of endless\n",
    "3. print 3 more iterations of e, hard coded as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd258f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/09 08/17 07/24 06/30 09/39 08/47 \n",
      "discarding 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(6, 9, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "1\n",
    "# from ...\n",
    "\n",
    "# def endless():\n",
    "#     ...\n",
    "\n",
    "# e = endless()\n",
    "\n",
    "2\n",
    "# total = 0\n",
    "# for i in e:\n",
    "#     if total < 40:\n",
    "#         total += i\n",
    "#         print(f\"{i:02d}/{total:02d}\", end=\" \")\n",
    "#     else:\n",
    "#         print()\n",
    "#         print(f\"discarding {i}\")\n",
    "#         break\n",
    "\n",
    "3\n",
    "# ...\n",
    "\n",
    "# solution\n",
    "\n",
    "1\n",
    "from itertools import cycle\n",
    "\n",
    "def endless():\n",
    "    \"\"\"Yields 9, 8, 7, 6, 9, 8, 7, 6, ... forever\"\"\"\n",
    "    yield from cycle((9, 8, 7, 6))\n",
    "e = endless()\n",
    "\n",
    "2\n",
    "total = 0\n",
    "for i in e:\n",
    "    if total < 40:\n",
    "        total += i\n",
    "        print(f\"{i:02d}/{total:02d}\", end=\" \")\n",
    "    else:\n",
    "        print()\n",
    "        print(f\"discarding {i}\")\n",
    "        break\n",
    "\n",
    "3\n",
    "next(e), next(e), next(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ca90b",
   "metadata": {},
   "source": [
    "### 002.006 asynchronous generator\n",
    "\n",
    "asynchronous iterators and asynchronous generators are not designed to concurrently map some function over a sequence or iterator. They’re merely designed to let the enclosing coroutine allow other tasks to take their turn. The async for and async with statements are only needed to the extent that using plain for or with would “break” the nature of await in the coroutine. This distinction between asynchronicity and concurrency is a key one to grasp.\n",
    "\n",
    "1. `mygen` is an async generator\n",
    "    1. It yields a sequence of powers of 2 up to 10\n",
    "    1. IT prints a separator (`.` for example) at each iteration\n",
    "    1. In between each yield there is a 0.2 sec async pause\n",
    "1. `main` is a a wrapper for async iterator and comprehension\n",
    "    1. `g` uses a list comprehension to put all the items generated by mygen in a list\n",
    "    1. `f` uses for loop to put all the items generated by mygen in a list, but only if i is not 3 or 5\n",
    "    1. Both are returned as a tuple\n",
    "1. Get the tuples and print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efff1338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ". . . . . . . . . . \n",
      "+ + + + + + + + + + "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 8, 16, 32, 64, 128, 256, 512]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 16, 32, 256, 512]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "\n",
    "# 1\n",
    "# async def mygen(sep:str, up_to: int = 10):\n",
    "#     print()\n",
    "#     i = 0\n",
    "#     for i in range(up_to):\n",
    "#         print(sep, end=\" \")\n",
    "#         ...\n",
    "\n",
    "# 2\n",
    "# async def main():\n",
    "#     g = ...\n",
    "\n",
    "#     f = []\n",
    "#     async for j in mygen(\"+\"):\n",
    "#         if j // 3 % 5:\n",
    "#             continue\n",
    "#         f.append(j)\n",
    "#     return g, f\n",
    "\n",
    "3\n",
    "# g, f =\n",
    "\n",
    "# g\n",
    "# f\n",
    "\n",
    "# solution\n",
    "\n",
    "1\n",
    "async def mygen(sep:str, up_to: int = 10):\n",
    "    print()\n",
    "    i = 0\n",
    "    for i in range(up_to):\n",
    "        print(sep, end=\" \")\n",
    "        yield 2 ** i\n",
    "        await asyncio.sleep(0.2)\n",
    "\n",
    "2\n",
    "async def main():\n",
    "    g = [i async for i in mygen(\".\")]\n",
    "\n",
    "    f = []\n",
    "    async for j in mygen(\"+\"):\n",
    "        if j // 3 % 5:\n",
    "            continue\n",
    "        f.append(j)\n",
    "    return g, f\n",
    "\n",
    "3\n",
    "g, f = asyncio.run(main())\n",
    "\n",
    "g\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cfba94",
   "metadata": {},
   "source": [
    "### 002.007 Async web scraper\n",
    "\n",
    "In this section, you’ll build a web-scraping URL collector, areq.py, using aiohttp, a blazingly fast async HTTP client/server framework. (We just need the client part.) Such a tool could be used to map connections between a cluster of sites, with the links forming a directed graph.\n",
    "\n",
    "1. `fetch_html` sends a get request to a url and returns the HTML content\n",
    "    1. Use the appropriate method to send an async get request (passing kwargs)\n",
    "    1. make the response handle any >= 400 request by raising\n",
    "    1. get the source code (HTML but it will work for .txt files too in fact)\n",
    "1. `parse` returns the links found in the source\n",
    "    1. catch all the aiohttp errors and print them\n",
    "    1. For each link, try and create an absolute link by joining them to the page's url (if they are relative) or not if not needed\n",
    "    1. Q: Why does it work?\n",
    "1. `write_one` uses  aiofiles to open files asynchronousloy and write a line at the time\n",
    "1. `bulk_crawl_and_write` creates a task per url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c11a6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aioHTTP error: 403, message='Forbidden', url=URL('https://www.politico.com/tipsheets/morning-money')\n",
      "Got response [200] for URL: https://www.ietf.org/rfc/rfc2616.txt\n",
      "Found 0 links for https://www.ietf.org/rfc/rfc2616.txt\n",
      "Got response [200] for URL: https://regex101.com/\n",
      "Found 6 links for https://regex101.com/\n",
      "Wrote results for source URL: https://regex101.com/\n",
      "aioHTTP error: 404, message='Not Found', url=URL('https://docs.python.org/3/this-url-will-404.html')\n",
      "Got response [200] for URL: https://www.bloomberg.com/markets/economics\n",
      "Found 0 links for https://www.bloomberg.com/markets/economics\n",
      "Got response [200] for URL: https://www.mediamatters.org/\n",
      "Found 6 links for https://www.mediamatters.org/\n",
      "Wrote results for source URL: https://www.mediamatters.org/\n",
      "Got response [200] for URL: https://1.1.1.1/\n",
      "Found 13 links for https://1.1.1.1/\n",
      "Wrote results for source URL: https://1.1.1.1/\n",
      "aioHTTP error: 404, message='Not Found', url=URL('https://archive.nytimes.com/www.nytimes.com/guides/')\n"
     ]
    }
   ],
   "source": [
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import aiofiles\n",
    "import aiohttp\n",
    "import re\n",
    "import urllib\n",
    "from aiohttp import ClientSession\n",
    "from pathlib import Path\n",
    "from typing import IO\n",
    "\n",
    "outpath = Path(\"_002_python_real_python_urls.txt\")\n",
    "urls = [\n",
    "    \"https://regex101.com/\",\n",
    "    \"https://docs.python.org/3/this-url-will-404.html\",\n",
    "    \"https://www.nytimes.com/guides/\",\n",
    "    \"https://www.mediamatters.org/\",\n",
    "    \"https://1.1.1.1/\",\n",
    "    \"https://www.politico.com/tipsheets/morning-money\",\n",
    "    \"https://www.bloomberg.com/markets/economics\",\n",
    "    \"https://www.ietf.org/rfc/rfc2616.txt\"\n",
    "]\n",
    "\n",
    "HREF_RE = re.compile(r'href=\"(http.*?)\"')\n",
    "\n",
    "# 1\n",
    "# async def fetch_html(url: str, session: ClientSession, **kwargs) -> str:\n",
    "#     \"\"\"GET request wrapper to fetch page HTML.\"\"\"\n",
    "\n",
    "#     resp = ... 1\n",
    "#     ... 2\n",
    "#     print(\"Got response [%s] for URL: %s\" % (resp.status, url))\n",
    "#     html = ...\n",
    "#     return html\n",
    "\n",
    "# 2\n",
    "# async def parse(url: str, session: ClientSession, **kwargs) -> set:\n",
    "#     \"\"\"Find HREFs in the HTML of `url`.\"\"\"\n",
    "\n",
    "#     found = set()\n",
    "#     try:\n",
    "#         html = await fetch_html(url=url, session=session, **kwargs)\n",
    "#     except (\n",
    "#         ...,\n",
    "#         ...,\n",
    "#     ) as e:\n",
    "#         print(\"aioHTTP error: %s\" % e)\n",
    "#         return found\n",
    "#     except Exception as e:\n",
    "#         print(\"non aioHTTP error: %s\" % e)\n",
    "#         return found\n",
    "#     else:\n",
    "#         for link in HREF_RE.findall(html):\n",
    "#             try:\n",
    "#                 # Q: Why does it work?\n",
    "#                 abslink = ...\n",
    "#             except (urllib.error.URLError, ValueError):\n",
    "#                 print(\"Error parsing URL: %s\" % link)\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 found.add(abslink)\n",
    "#         print(\"Found %d links for %s\" % ( len(found), url))\n",
    "#         return found\n",
    "\n",
    "# 3\n",
    "# async def write_one(file: IO, url: str, **kwargs) -> None:\n",
    "#     \"\"\"Write the found HREFs from `url` to `file`.\"\"\"\n",
    "#     res = await parse(url=url, **kwargs)\n",
    "#     if not res:\n",
    "#         return None\n",
    "#     ...:\n",
    "#         for p in res:\n",
    "#             ...write(f\"{url}\\t{p}\\n\")\n",
    "#         print(\"Wrote results for source URL: %s\" % url)\n",
    "\n",
    "# 4\n",
    "# async def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -> None:\n",
    "#     async with ClientSession() as session:\n",
    "#         tasks = []\n",
    "#         for url in urls:\n",
    "#             ...\n",
    "#         await asyncio.gather(*tasks)\n",
    "\n",
    "# 5\n",
    "# with open(outpath, \"w\") as outfile:\n",
    "#     outfile.write(\"source_url\\tparsed_url\\n\")\n",
    "# asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls))\n",
    "\n",
    "\n",
    "# solution\n",
    "\n",
    "1\n",
    "async def fetch_html(url: str, session: ClientSession, **kwargs) -> str:\n",
    "    \"\"\"GET request wrapper to fetch page HTML.\"\"\"\n",
    "\n",
    "    resp = await session.request(method=\"GET\", url=url, **kwargs)\n",
    "    resp.raise_for_status()\n",
    "    print(\"Got response [%s] for URL: %s\" % (resp.status, url))\n",
    "    html = await resp.text()\n",
    "    return html\n",
    "\n",
    "2\n",
    "async def parse(url: str, session: ClientSession, **kwargs) -> set:\n",
    "    \"\"\"Find HREFs in the HTML of `url`.\"\"\"\n",
    "\n",
    "    found = set()\n",
    "    try:\n",
    "        html = await fetch_html(url=url, session=session, **kwargs)\n",
    "    except (\n",
    "        aiohttp.ClientError,\n",
    "        aiohttp.http_exceptions.HttpProcessingError,\n",
    "    ) as e:\n",
    "        print(\"aioHTTP error: %s\" % e)\n",
    "        return found\n",
    "    except Exception as e:\n",
    "        print(\"non aioHTTP error: %s\" % e)\n",
    "        return found\n",
    "    else:\n",
    "        for link in HREF_RE.findall(html):\n",
    "            # because urljoin will do the right thing and ignore url if link is absolute\n",
    "            try:\n",
    "                abslink = urllib.parse.urljoin(url, link)\n",
    "            except (urllib.error.URLError, ValueError):\n",
    "                print(\"Error parsing URL: %s\" % link)\n",
    "                pass\n",
    "            else:\n",
    "                found.add(abslink)\n",
    "        print(\"Found %d links for %s\" % ( len(found), url))\n",
    "        return found\n",
    "\n",
    "3\n",
    "async def write_one(file: IO, url: str, **kwargs) -> None:\n",
    "    \"\"\"Write the found HREFs from `url` to `file`.\"\"\"\n",
    "    res = await parse(url=url, **kwargs)\n",
    "    if not res:\n",
    "        return None\n",
    "    async with aiofiles.open(file, \"a\") as f:\n",
    "        for p in res:\n",
    "            await f.write(f\"{url}\\t{p}\\n\")\n",
    "        print(\"Wrote results for source URL: %s\" % url)\n",
    "\n",
    "4\n",
    "async def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -> None:\n",
    "    async with ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in urls:\n",
    "            tasks.append(\n",
    "                write_one(file=file, url=url, session=session, **kwargs)\n",
    "            )\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "5\n",
    "with open(outpath, \"w\") as outfile:\n",
    "    outfile.write(\"source_url\\tparsed_url\\n\")\n",
    "asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265bdb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_url\tparsed_url\n",
      "https://regex101.com/\thttps://fonts.googleapis.com\n",
      "https://regex101.com/\thttps://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;1,400&family=Source+Code+Pro:wght@400;500;700&display=swap\n",
      "https://regex101.com/\thttps://regex101.com\n",
      "https://regex101.com/\thttps://turnonjs.com\n",
      "https://regex101.com/\thttp://browsehappy.com/\n",
      "https://regex101.com/\thttps://fonts.gstatic.com\n",
      "https://www.mediamatters.org/\thttps://www.youtube.com/channel/UC_70iWZ6ym2cglS_kv5YfmA\n",
      "https://www.mediamatters.org/\thttps://www.instagram.com/mediamattersforamerica/\n",
      "https://www.mediamatters.org/\thttps://www.mediamatters.org/\n",
      "https://www.mediamatters.org/\thttps://action.mediamatters.org/secure/donate\n",
      "https://www.mediamatters.org/\thttps://twitter.com/mmfa\n",
      "https://www.mediamatters.org/\thttps://www.facebook.com/Mediamatters/\n",
      "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/windows/\n",
      "https://1.1.1.1/\thttps://www.cloudflare.com/careers/departments/\n",
      "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/linux/\n",
      "https://1.1.1.1/\thttps://pkg.cloudflareclient.com/\n",
      "https://1.1.1.1/\thttps://1111-releases.cloudflareclient.com/windows/Cloudflare_WARP_Release-x64.msi\n",
      "https://1.1.1.1/\thttps://cloudflare.com\n",
      "https://1.1.1.1/\thttps://1111-releases.cloudflareclient.com/mac/Cloudflare_WARP.zip\n",
      "https://1.1.1.1/\thttps://blog.cloudflare.com/warp-for-desktop\n",
      "https://1.1.1.1/\thttps://twitter.com/intent/tweet?text=ISPs%20spy%20on%20your%20Internet%20traffic%20and%20sell%20the%20data.%20I%27m%20using%201.1.1.1%20with%20WARP%2C%20a%20free%20app%20which%20makes%20the%20Internet%20on%20my%20phone%20faster%20and%20more%20private.%20You%20should%20get%20the%20app%20too%3A%20https%3A//one.one.one.one\n",
      "https://1.1.1.1/\thttps://itunes.apple.com/us/app/1-1-1-1-faster-internet/id1423538627\n",
      "https://1.1.1.1/\thttps://1.1.1.1\n",
      "https://1.1.1.1/\thttps://play.google.com/store/apps/details?id=com.cloudflare.onedotonedotonedotone\n",
      "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/macOS/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat _002_python_real_python_urls.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7daeb9a356073df578df6d7584369b7908e732a3e4cb2289ee7d810fc6635fc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
