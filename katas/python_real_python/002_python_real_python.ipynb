{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99786a37",
   "metadata": {},
   "source": [
    "# Async IO in Python: A Complete Walkthrough\n",
    "\n",
    "Async IO is a concurrent programming design that has received dedicated support in Python, evolving rapidly from Python 3.4 through 3.7, and probably beyond.\n",
    "\n",
    "<https://realpython.com/async-io-python/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89ce8c2b",
   "metadata": {},
   "source": [
    "## 001. Synchronous Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb605f4",
   "metadata": {},
   "source": [
    "**Parallelism** consists of performing multiple operations at the same time. **Multiprocessing** is a means to effect parallelism, and it entails spreading tasks over a computer’s central processing units (CPUs, or cores). Multiprocessing is well-suited for CPU-bound tasks: tightly bound for loops and mathematical computations usually fall into this category.\n",
    "\n",
    "**Concurrency** is a slightly broader term than parallelism. It suggests that multiple tasks have the ability to run in an overlapping manner. (There’s a saying that concurrency does not imply parallelism.)\n",
    "\n",
    "**Threading** is a concurrent execution model whereby multiple threads take turns executing tasks. One process can contain multiple threads. Python has a complicated relationship with threading thanks to its GIL, but that’s beyond the scope of this article.\n",
    "\n",
    "async IO is a single-threaded, single-process design: it uses **cooperative multitasking**. It has been said in other words that async IO gives a feeling of concurrency despite using a single thread in a single process. Coroutines (a central feature of async IO) can be scheduled concurrently, but they are not inherently concurrent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ca7850",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:02.945669Z",
     "iopub.status.busy": "2024-03-18T14:37:02.945257Z",
     "iopub.status.idle": "2024-03-18T14:37:02.955467Z",
     "shell.execute_reply": "2024-03-18T14:37:02.955127Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9ad49b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:02.957168Z",
     "iopub.status.busy": "2024-03-18T14:37:02.957051Z",
     "iopub.status.idle": "2024-03-18T14:37:04.256750Z",
     "shell.execute_reply": "2024-03-18T14:37:04.256165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q faker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263c4dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.259440Z",
     "iopub.status.busy": "2024-03-18T14:37:04.259193Z",
     "iopub.status.idle": "2024-03-18T14:37:04.383547Z",
     "shell.execute_reply": "2024-03-18T14:37:04.383255Z"
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "fake = Faker()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b212460",
   "metadata": {},
   "source": [
    "### 002.001 The async/await Syntax and Native Coroutines\n",
    "\n",
    "Let’s take the immersive approach and write some async IO code. This short program is the Hello World of async IO but goes a long way towards illustrating its core functionality:\n",
    "\n",
    "1. Create a function `count_sync`\n",
    "    1. after printing, it waits synchronously 1 sec, then prints two\n",
    "1. Create a function `main_sync`\n",
    "    1. it runs `count_sync` in sequence 3 times\n",
    "1. Create a function `count_async`\n",
    "    1. after printing, it waits asynchronously 1 sec, then prints two\n",
    "1. Create a function `main_async`\n",
    "    1. it runs `count_async` asynchronously 3 times\n",
    "1. The output should be One Two One ... for the sync version, taking 3 s. And One One ... for the async one, taking sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c741ca30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.385298Z",
     "iopub.status.busy": "2024-03-18T14:37:04.385215Z",
     "iopub.status.idle": "2024-03-18T14:37:04.394843Z",
     "shell.execute_reply": "2024-03-18T14:37:04.394398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "1\n",
    "# def count_sync():\n",
    "#     print(\"One Sync\")\n",
    "#     ...\n",
    "#     print(\"two sync\")\n",
    "\n",
    "2\n",
    "# def main_sync():\n",
    "#     ...\n",
    "\n",
    "3\n",
    "# async def count_async():\n",
    "#     print(\"One Async\")\n",
    "#     ...\n",
    "#     print(\"two async\")\n",
    "\n",
    "\n",
    "4\n",
    "# async def main_async():\n",
    "#     ...\n",
    "\n",
    "5\n",
    "# s = time.perf_counter()\n",
    "# main_sync()\n",
    "# elapsed = time.perf_counter() - s\n",
    "# print(f\"sync version executed in {elapsed:0.2f} seconds.\")\n",
    "\n",
    "# s = time.perf_counter()\n",
    "# asyncio.run(main_async())\n",
    "# elapsed = time.perf_counter() - s\n",
    "# print(f\"async version executed in {elapsed:0.2f} seconds.\")\n",
    "\n",
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce0b85",
   "metadata": {},
   "source": [
    "### 002.002 The Rules of Async IO\n",
    "\n",
    "Here’s one example of how async IO cuts down on wait time: given a coroutine makerandom() that keeps producing random integers in the range [0, 10], until one of them exceeds a threshold, you want to let multiple calls of this coroutine not need to wait for each other to complete in succession. You can largely follow the patterns from the two scripts above, with slight changes\n",
    "\n",
    "1. `makerandom` \n",
    "    1. should keep generating `i` until one it's greater than threshold.\n",
    "    1. if it isn't, it should print f\"{i} too low; retrying.\",\n",
    "    1. then sleep asynchronously for `i + 1` seconds, \n",
    "    1. the generate a new one\n",
    "1. `main`\n",
    "    1. should run 3 makerandom with idx in range 0 to 2 asynchronously\n",
    "1. should gather the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b4db5ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.396519Z",
     "iopub.status.busy": "2024-03-18T14:37:04.396426Z",
     "iopub.status.idle": "2024-03-18T14:37:04.399882Z",
     "shell.execute_reply": "2024-03-18T14:37:04.399667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import random\n",
    "\n",
    "# ANSI colors\n",
    "c = (\n",
    "    \"\\033[0m\",   # End of color\n",
    "    \"\\033[36m\",  # Cyan\n",
    "    \"\\033[91m\",  # Red\n",
    "    \"\\033[35m\",  # Magenta\n",
    ")\n",
    "\n",
    "# f\"{i} too low; retrying.\"\n",
    "\n",
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "OFFSET = 8\n",
    "\n",
    "1\n",
    "# async def makerandom(idx: int, threshold: int = 6) -> int:\n",
    "#     threshold = OFFSET - idx - 1\n",
    "#     print(c[idx + 1] + f\"Initiated makerandom({idx=}, {threshold=}).\" + c[0])\n",
    "#     i = random.randint(0, OFFSET)\n",
    "#     ...\n",
    "#     print(c[idx + 1] + f\"---> Finished: makerandom({idx}) == {i}\" + c[0])\n",
    "#     return i\n",
    "\n",
    "2\n",
    "# async def main():\n",
    "#     ..\n",
    "#     return res\n",
    "\n",
    "3\n",
    "# random.seed(444)\n",
    "# r1, r2, r3 = asyncio.run(main())\n",
    "# print(f\"r1: {r1}, r2: {r2}, r3: {r3}\")\n",
    "\n",
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139bfb11",
   "metadata": {},
   "source": [
    "### 002.003 Chaining Coroutines\n",
    "\n",
    "A key feature of coroutines is that they can be chained together. (Remember, a coroutine object is awaitable, so another coroutine can await it.) This allows you to break programs into smaller, manageable, recyclable coroutines:\n",
    "\n",
    "1. `load` \n",
    "    1. waits i secs, asynchronously\n",
    "    1. returns i\n",
    "1. `fire`\n",
    "    1. waits i secs, asynchronously\n",
    "    1. returns i plus the i from the following step as a tuple\n",
    "1. `chain`\n",
    "    1. runs load and puts result in `p1`\n",
    "    1. then feeds result to fire and puts result in `p2`\n",
    "1. `main`\n",
    "    1. initiates an instance of `chain` for each arg, concurrently\n",
    "1. finally\n",
    "    1. runs all the jobs in `main`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b84ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.401336Z",
     "iopub.status.busy": "2024-03-18T14:37:04.401238Z",
     "iopub.status.idle": "2024-03-18T14:37:04.405374Z",
     "shell.execute_reply": "2024-03-18T14:37:04.405153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "1\n",
    "# async def load(n: str) -> int:\n",
    "#     i = random.randint(0, 10)\n",
    "#     print(f\"loading {n}: (will take {i} seconds)\")\n",
    "#     ...\n",
    "#     print(f\"{n} loaded..\")\n",
    "#     ...\n",
    "\n",
    "2\n",
    "# async def fire(n: str, last_i: int) -> tuple[int, int]:\n",
    "#     i = random.randint(0, 10)\n",
    "#     print(f\"firing {n}: (will take {i} seconds)\")\n",
    "#     ...\n",
    "#     print(f\"{n} fired!\")\n",
    "#     return (last_i, i)\n",
    "\n",
    "3\n",
    "# async def chain(n: str) -> None:\n",
    "#     start = time.perf_counter()\n",
    "#     ...\n",
    "#     ...\n",
    "#     end = time.perf_counter() - start\n",
    "#     print(f\"--> Timing for {n}: total {end:0.2f} seconds, partial {p2}.\")\n",
    "\n",
    "4\n",
    "# async def main(*args):\n",
    "#     ...\n",
    "\n",
    "5\n",
    "# random.seed(1672)\n",
    "# args = [\"cannon\", \"laser\", \"railgun\"]\n",
    "# start = time.perf_counter()\n",
    "# ...\n",
    "# end = time.perf_counter() - start\n",
    "# print(f\"Program finished in {end:0.2f} seconds.\")\n",
    "\n",
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05aefde",
   "metadata": {},
   "source": [
    "### 002.004 Using a Queue\n",
    "\n",
    "There is an alternative structure that can also work with async IO: a number of producers, which are not associated with each other, add items to a queue. Each producer may add multiple items to the queue at staggered, random, unannounced times. A group of consumers pull items from the queue as they show up, greedily and without waiting for any other signal. One use-case for queues (as is the case here) is for the queue to act as a transmitter for producers and consumers that aren’t otherwise directly chained or associated with each other.\n",
    "\n",
    "\n",
    "1. `produce` pushes a random number of jobs to the queue\n",
    "    1. Use the itertools method that allows to returns a list of n somethings (in this case, None)\n",
    "    1. Add a tuple (an actual tuple) to the queue: first item is a random job, the other is a timestamp CAREFUL HERE, YOU ALWAYS MAKE SAME MISTAKE\n",
    "1. `consumer` gets the next available job and processes it\n",
    "    1. Q: we are using `while True`, isn't that going to cause problems?\n",
    "    1. Get the tuple off the queue\n",
    "    1. Tell the queue it can tick the job as complete\n",
    "1. `main` orchestrates the whole thing\n",
    "    1. create a queue\n",
    "    1. create and schedule a set with a task for each producer\n",
    "    1. make sure each of these tasks gets eventually garbage collected\n",
    "    1. do the same for consumer (use male names)\n",
    "    1. run all the producers tasks\n",
    "    1. Q: why only the producers?\n",
    "    1. wait until all jobs are processed\n",
    "    1. Q: how do we know we are done?\n",
    "    1. turn off the consumers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05780379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.406879Z",
     "iopub.status.busy": "2024-03-18T14:37:04.406806Z",
     "iopub.status.idle": "2024-03-18T14:37:04.411040Z",
     "shell.execute_reply": "2024-03-18T14:37:04.410799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import itertools as it\n",
    "import random\n",
    "import time\n",
    "\n",
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "NPROD = 3\n",
    "\n",
    "async def create_job(size: int = 5) -> str:\n",
    "    return fake.job()\n",
    "\n",
    "async def rand_sleep() -> None:\n",
    "    i = random.randint(0, 10)\n",
    "    await asyncio.sleep(i)\n",
    "\n",
    "1\n",
    "# async def produce(name: str, q: asyncio.Queue) -> None:\n",
    "#     n = random.randint(0, 10)\n",
    "#     for _ in ...\n",
    "#         await rand_sleep()\n",
    "#         i = await create_job()\n",
    "#         t = time.perf_counter()\n",
    "#         ...\n",
    "#         print(f\"Producer {name} added <{i}> to queue.\")\n",
    "\n",
    "2\n",
    "# async def consume(name: int, q: asyncio.Queue) -> None:\n",
    "#     while True:\n",
    "#         await rand_sleep()\n",
    "#         ...\n",
    "#         now = time.perf_counter()\n",
    "#         print(f\"    > Consumer {name} got element <{i}>\"\n",
    "#               f\" in {now-t:0.5f} seconds.\")\n",
    "#         ...\n",
    "\n",
    "3\n",
    "# async def main(nprod: int, ncon: int):\n",
    "#     q = ...\n",
    "#     producers = set()\n",
    "#     for _ in range(nprod):\n",
    "#         task = ...produce(fake.first_name_female(), q)\n",
    "#         producers.add(task)\n",
    "#         ...\n",
    "#     consumers = set()\n",
    "#     for _ in range(ncon):\n",
    "#         task = ...\n",
    "#         consumers.add(task)\n",
    "#         ...\n",
    "#     ...\n",
    "#     ...\n",
    "#     for c in consumers:\n",
    "#         ...\n",
    "\n",
    "\n",
    "# random.seed(444)\n",
    "# start = time.perf_counter()\n",
    "# asyncio.run(main(nprod=NPROD, ncon=2))\n",
    "# elapsed = time.perf_counter() - start\n",
    "# print(f\"Program completed in {elapsed:0.5f} seconds.\")\n",
    "\n",
    "\n",
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82df488",
   "metadata": {},
   "source": [
    "### 002.005 Async IO’s Roots in Generators\n",
    "\n",
    "The await keyword behaves similarly, marking a break point at which the coroutine suspends itself and lets other coroutines work. “Suspended,” in this case, means a coroutine that has temporarily ceded control but not totally exited or finished. Keep in mind that yield, and by extension yield from and await, mark a break point in a generator’s execution.\n",
    "\n",
    "1. `endless` is a generator that each time next is called on it returns one of 9,8,7,6,9...\n",
    "    1. Import the relevant package\n",
    "2. use `for ... in ` to print a few iterations of endless\n",
    "3. print 3 more iterations of e, hard coded as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd258f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.412456Z",
     "iopub.status.busy": "2024-03-18T14:37:04.412360Z",
     "iopub.status.idle": "2024-03-18T14:37:04.415203Z",
     "shell.execute_reply": "2024-03-18T14:37:04.415006Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "1\n",
    "# from ...\n",
    "\n",
    "# def endless():\n",
    "#     ...\n",
    "\n",
    "# e = endless()\n",
    "\n",
    "2\n",
    "# total = 0\n",
    "# for i in e:\n",
    "#     if total < 40:\n",
    "#         total += i\n",
    "#         print(f\"{i:02d}/{total:02d}\", end=\" \")\n",
    "#     else:\n",
    "#         print()\n",
    "#         print(f\"discarding {i}\")\n",
    "#         break\n",
    "\n",
    "3\n",
    "# ...\n",
    "\n",
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2ca90b",
   "metadata": {},
   "source": [
    "### 002.006 asynchronous generator\n",
    "\n",
    "asynchronous iterators and asynchronous generators are not designed to concurrently map some function over a sequence or iterator. They’re merely designed to let the enclosing coroutine allow other tasks to take their turn. The async for and async with statements are only needed to the extent that using plain for or with would “break” the nature of await in the coroutine. This distinction between asynchronicity and concurrency is a key one to grasp.\n",
    "\n",
    "1. `mygen` is an async generator\n",
    "    1. It yields a sequence of powers of 2 up to 10\n",
    "    1. IT prints a separator (`.` for example) at each iteration\n",
    "    1. In between each yield there is a 0.2 sec async pause\n",
    "1. `main` is a a wrapper for async iterator and comprehension\n",
    "    1. `g` uses a list comprehension to put all the items generated by mygen in a list\n",
    "    1. `f` uses for loop to put all the items generated by mygen in a list, but only if i is not 3 or 5\n",
    "    1. Both are returned as a tuple\n",
    "1. Get the tuples and print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efff1338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.416510Z",
     "iopub.status.busy": "2024-03-18T14:37:04.416419Z",
     "iopub.status.idle": "2024-03-18T14:37:04.418723Z",
     "shell.execute_reply": "2024-03-18T14:37:04.418486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "\n",
    "# 1\n",
    "# async def mygen(sep:str, up_to: int = 10):\n",
    "#     print()\n",
    "#     i = 0\n",
    "#     for i in range(up_to):\n",
    "#         print(sep, end=\" \")\n",
    "#         ...\n",
    "\n",
    "# 2\n",
    "# async def main():\n",
    "#     g = ...\n",
    "\n",
    "#     f = []\n",
    "#     async for j in mygen(\"+\"):\n",
    "#         if j // 3 % 5:\n",
    "#             continue\n",
    "#         f.append(j)\n",
    "#     return g, f\n",
    "\n",
    "3\n",
    "# g, f =\n",
    "\n",
    "# g\n",
    "# f\n",
    "\n",
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cfba94",
   "metadata": {},
   "source": [
    "### 002.007 Async web scraper\n",
    "\n",
    "In this section, you’ll build a web-scraping URL collector, areq.py, using aiohttp, a blazingly fast async HTTP client/server framework. (We just need the client part.) Such a tool could be used to map connections between a cluster of sites, with the links forming a directed graph.\n",
    "\n",
    "1. `fetch_html` sends a get request to a url and returns the HTML content\n",
    "    1. Use the appropriate method to send an async get request (passing kwargs)\n",
    "    1. make the response handle any >= 400 request by raising\n",
    "    1. get the source code (HTML but it will work for .txt files too in fact)\n",
    "1. `parse` returns the links found in the source\n",
    "    1. catch all the aiohttp errors and print them\n",
    "    1. For each link, try and create an absolute link by joining them to the page's url (if they are relative) or not if not needed\n",
    "    1. Q: Why does it work?\n",
    "1. `write_one` uses  aiofiles to open files asynchronousloy and write a line at the time\n",
    "1. `bulk_crawl_and_write` creates a task per url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c11a6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.420310Z",
     "iopub.status.busy": "2024-03-18T14:37:04.420225Z",
     "iopub.status.idle": "2024-03-18T14:37:04.693881Z",
     "shell.execute_reply": "2024-03-18T14:37:04.693252Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is needed to make asyncio run inside notebooks, without the\n",
    "# This event loop is already running RunTimeError\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import aiofiles\n",
    "import aiohttp\n",
    "import re\n",
    "import urllib\n",
    "from aiohttp import ClientSession\n",
    "from pathlib import Path\n",
    "from typing import IO\n",
    "\n",
    "outpath = Path(\"_002_python_real_python_urls.txt\")\n",
    "urls = [\n",
    "    \"https://regex101.com/\",\n",
    "    \"https://docs.python.org/3/this-url-will-404.html\",\n",
    "    \"https://www.nytimes.com/guides/\",\n",
    "    \"https://www.mediamatters.org/\",\n",
    "    \"https://1.1.1.1/\",\n",
    "    \"https://www.politico.com/tipsheets/morning-money\",\n",
    "    \"https://www.bloomberg.com/markets/economics\",\n",
    "    \"https://www.ietf.org/rfc/rfc2616.txt\"\n",
    "]\n",
    "\n",
    "HREF_RE = re.compile(r'href=\"(http.*?)\"')\n",
    "\n",
    "# 1\n",
    "# async def fetch_html(url: str, session: ClientSession, **kwargs) -> str:\n",
    "#     \"\"\"GET request wrapper to fetch page HTML.\"\"\"\n",
    "\n",
    "#     resp = ... 1\n",
    "#     ... 2\n",
    "#     print(\"Got response [%s] for URL: %s\" % (resp.status, url))\n",
    "#     html = ...\n",
    "#     return html\n",
    "\n",
    "# 2\n",
    "# async def parse(url: str, session: ClientSession, **kwargs) -> set:\n",
    "#     \"\"\"Find HREFs in the HTML of `url`.\"\"\"\n",
    "\n",
    "#     found = set()\n",
    "#     try:\n",
    "#         html = await fetch_html(url=url, session=session, **kwargs)\n",
    "#     except (\n",
    "#         ...,\n",
    "#         ...,\n",
    "#     ) as e:\n",
    "#         print(\"aioHTTP error: %s\" % e)\n",
    "#         return found\n",
    "#     except Exception as e:\n",
    "#         print(\"non aioHTTP error: %s\" % e)\n",
    "#         return found\n",
    "#     else:\n",
    "#         for link in HREF_RE.findall(html):\n",
    "#             try:\n",
    "#                 # Q: Why does it work?\n",
    "#                 abslink = ...\n",
    "#             except (urllib.error.URLError, ValueError):\n",
    "#                 print(\"Error parsing URL: %s\" % link)\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 found.add(abslink)\n",
    "#         print(\"Found %d links for %s\" % ( len(found), url))\n",
    "#         return found\n",
    "\n",
    "# 3\n",
    "# async def write_one(file: IO, url: str, **kwargs) -> None:\n",
    "#     \"\"\"Write the found HREFs from `url` to `file`.\"\"\"\n",
    "#     res = await parse(url=url, **kwargs)\n",
    "#     if not res:\n",
    "#         return None\n",
    "#     ...:\n",
    "#         for p in res:\n",
    "#             ...write(f\"{url}\\t{p}\\n\")\n",
    "#         print(\"Wrote results for source URL: %s\" % url)\n",
    "\n",
    "# 4\n",
    "# async def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -> None:\n",
    "#     async with ClientSession() as session:\n",
    "#         tasks = []\n",
    "#         for url in urls:\n",
    "#             ...\n",
    "#         await asyncio.gather(*tasks)\n",
    "\n",
    "# 5\n",
    "# with open(outpath, \"w\") as outfile:\n",
    "#     outfile.write(\"source_url\\tparsed_url\\n\")\n",
    "# asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls))\n",
    "\n",
    "\n",
    "# solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265bdb9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T14:37:04.696955Z",
     "iopub.status.busy": "2024-03-18T14:37:04.696682Z",
     "iopub.status.idle": "2024-03-18T14:37:04.722549Z",
     "shell.execute_reply": "2024-03-18T14:37:04.722140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_url\tparsed_url\n",
      "https://regex101.com/\thttps://fonts.googleapis.com\n",
      "https://regex101.com/\thttps://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;1,400&family=Source+Code+Pro:wght@400;500;700&display=swap\n",
      "https://regex101.com/\thttps://regex101.com\n",
      "https://regex101.com/\thttps://turnonjs.com\n",
      "https://regex101.com/\thttp://browsehappy.com/\n",
      "https://regex101.com/\thttps://fonts.gstatic.com\n",
      "https://www.mediamatters.org/\thttps://www.youtube.com/channel/UC_70iWZ6ym2cglS_kv5YfmA\n",
      "https://www.mediamatters.org/\thttps://www.instagram.com/mediamattersforamerica/\n",
      "https://www.mediamatters.org/\thttps://www.mediamatters.org/\n",
      "https://www.mediamatters.org/\thttps://action.mediamatters.org/secure/donate\n",
      "https://www.mediamatters.org/\thttps://twitter.com/mmfa\n",
      "https://www.mediamatters.org/\thttps://www.facebook.com/Mediamatters/\n",
      "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/windows/\n",
      "https://1.1.1.1/\thttps://www.cloudflare.com/careers/departments/\n",
      "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/linux/\n",
      "https://1.1.1.1/\thttps://pkg.cloudflareclient.com/\n",
      "https://1.1.1.1/\thttps://1111-releases.cloudflareclient.com/windows/Cloudflare_WARP_Release-x64.msi\n",
      "https://1.1.1.1/\thttps://cloudflare.com\n",
      "https://1.1.1.1/\thttps://1111-releases.cloudflareclient.com/mac/Cloudflare_WARP.zip\n",
      "https://1.1.1.1/\thttps://blog.cloudflare.com/warp-for-desktop\n",
      "https://1.1.1.1/\thttps://twitter.com/intent/tweet?text=ISPs%20spy%20on%20your%20Internet%20traffic%20and%20sell%20the%20data.%20I%27m%20using%201.1.1.1%20with%20WARP%2C%20a%20free%20app%20which%20makes%20the%20Internet%20on%20my%20phone%20faster%20and%20more%20private.%20You%20should%20get%20the%20app%20too%3A%20https%3A//one.one.one.one\n",
      "https://1.1.1.1/\thttps://itunes.apple.com/us/app/1-1-1-1-faster-internet/id1423538627\n",
      "https://1.1.1.1/\thttps://1.1.1.1\n",
      "https://1.1.1.1/\thttps://play.google.com/store/apps/details?id=com.cloudflare.onedotonedotonedotone\n",
      "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/macOS/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat _002_python_real_python_urls.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "7daeb9a356073df578df6d7584369b7908e732a3e4cb2289ee7d810fc6635fc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
