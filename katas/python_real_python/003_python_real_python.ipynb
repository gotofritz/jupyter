{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "99786a37", "metadata": {}, "source": ["# Bypassing the GIL for Parallel Processing in Python\n", "\n", "Unlocking Python's true potential in terms of speed through shared-memory parallelism has traditionally been limited and challenging to achieve. That's because the global interpreter lock (GIL) doesn't allow for thread-based parallel processing in Python. Fortunately, there are several work-arounds for this notorious limitation, which you're about to explore now!\n", "\n", "<https://realpython.com/python-parallel-processing/>"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from IPython.core.interactiveshell import InteractiveShell\n", "\n", "pd.set_option('display.max_rows', None)\n", "InteractiveShell.ast_node_interactivity = \"all\""]}, {"attachments": {}, "cell_type": "markdown", "id": "89ce8c2b", "metadata": {}, "source": ["## 001. Synchronous Version"]}, {"cell_type": "markdown", "id": "dcb605f4", "metadata": {}, "source": ["**Parallelism** consists of performing multiple operations at the same time. **Multiprocessing** is a means to effect parallelism, and it entails spreading tasks over a computer\u2019s central processing units (CPUs, or cores). Multiprocessing is well-suited for CPU-bound tasks: tightly bound for loops and mathematical computations usually fall into this category.\n", "\n", "**Concurrency** is a slightly broader term than parallelism. It suggests that multiple tasks have the ability to run in an overlapping manner. (There\u2019s a saying that concurrency does not imply parallelism.)\n", "\n", "**Threading** is a concurrent execution model whereby multiple threads take turns executing tasks. One process can contain multiple threads. Python has a complicated relationship with threading thanks to its GIL, but that\u2019s beyond the scope of this article.\n", "\n", "async IO is a single-threaded, single-process design: it uses **cooperative multitasking**. It has been said in other words that async IO gives a feeling of concurrency despite using a single thread in a single process. Coroutines (a central feature of async IO) can be scheduled concurrently, but they are not inherently concurrent."]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["from faker import Faker\n", "fake = Faker()"]}, {"attachments": {}, "cell_type": "markdown", "id": "5b212460", "metadata": {}, "source": ["### 002.001 The async/await Syntax and Native Coroutines\n", "\n", "Let\u2019s take the immersive approach and write some async IO code. This short program is the Hello World of async IO but goes a long way towards illustrating its core functionality:\n", "\n", "1. Create a function `count_sync`\n", "    1. after printing, it waits synchronously 1 sec, then prints two\n", "1. Create a function `main_sync`\n", "    1. it runs `count_sync` in sequence 3 times\n", "1. Create a function `count_async`\n", "    1. after printing, it waits asynchronously 1 sec, then prints two\n", "1. Create a function `main_async`\n", "    1. it runs `count_async` asynchronously 3 times\n", "1. The output should be One Two One ... for the sync version, taking 3 s. And One One ... for the async one, taking sec\n"]}, {"cell_type": "code", "execution_count": 4, "id": "c741ca30", "metadata": {}, "outputs": [], "source": ["\n", "import os\n", "import threading\n", "\n", "def fib(n):\n", "    return n if n < 2 else fib(n - 2) + fib(n - 1)\n", "\n", "for _ in range(os.cpu_count()):\n", "    threading.Thread(target=fib, args=(35,)).start()"]}, {"cell_type": "code", "execution_count": 5, "id": "ae7bff46", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["\n", "real\t0m12.083s\n", "user\t0m12.011s\n", "sys\t0m0.160s\n"]}], "source": ["%%bash\n", "\n", "time python 003_fibonacci.py"]}, {"cell_type": "code", "execution_count": 6, "id": "ccd8eaa6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["\n", "real\t0m2.860s\n", "user\t0m22.621s\n", "sys\t0m0.182s\n"]}], "source": ["%%bash\n", "\n", "time python 003_fibonacci2.py"]}, {"cell_type": "code", "execution_count": 7, "id": "90a3fedd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["fib(0) = 0\n", "fib(1) = 1\n", "fib(2) = 1\n", "fib(3) = 2\n", "fib(4) = 3\n", "fib(5) = 5\n", "fib(6) = 8\n", "fib(7) = 13\n", "fib(8) = 21\n", "fib(9) = 34\n", "fib(10) = 55\n", "fib(11) = 89\n", "fib(12) = 144\n", "fib(13) = 233\n", "fib(14) = 377\n", "fib(15) = 610\n", "fib(16) = 987\n", "fib(17) = 1597\n", "fib(18) = 2584\n", "fib(19) = 4181\n", "fib(20) = 6765\n", "fib(21) = 10946\n", "fib(22) = 17711\n", "fib(23) = 28657\n", "fib(24) = 46368\n", "fib(25) = 75025\n", "fib(26) = 121393\n", "fib(27) = 196418\n", "fib(28) = 317811\n", "fib(29) = 514229\n", "fib(30) = 832040\n", "fib(31) = 1346269\n", "fib(32) = 2178309\n", "fib(33) = 3524578\n", "fib(34) = 5702887\n", "fib(35) = 9227465\n", "fib(36) = 14930352\n", "fib(37) = 24157817\n", "fib(38) = 39088169\n", "fib(39) = 63245986\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n", "real\t0m16.681s\n", "user\t0m35.034s\n", "sys\t0m0.132s\n"]}], "source": ["%%bash\n", "\n", "time python 003_fibonacci3.py"]}, {"cell_type": "code", "execution_count": 8, "id": "6ccb6d81", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["fib(0) = 0\n", "fib(1) = 1\n", "fib(2) = 1\n", "fib(3) = 2\n", "fib(4) = 3\n", "fib(5) = 5\n", "fib(6) = 8\n", "fib(7) = 13\n", "fib(8) = 21\n", "fib(9) = 34\n", "fib(10) = 55\n", "fib(11) = 89\n", "fib(12) = 144\n", "fib(13) = 233\n", "fib(14) = 377\n", "fib(15) = 610\n", "fib(16) = 987\n", "fib(17) = 1597\n", "fib(18) = 2584\n", "fib(19) = 4181\n", "fib(20) = 6765\n", "fib(21) = 10946\n", "fib(22) = 17711\n", "fib(23) = 28657\n", "fib(24) = 46368\n", "fib(25) = 75025\n", "fib(26) = 121393\n", "fib(27) = 196418\n", "fib(28) = 317811\n", "fib(29) = 514229\n", "fib(30) = 832040\n", "fib(31) = 1346269\n", "fib(32) = 2178309\n", "fib(33) = 3524578\n", "fib(34) = 5702887\n", "fib(35) = 9227465\n", "fib(36) = 14930352\n", "fib(37) = 24157817\n", "fib(38) = 39088169\n", "fib(39) = 63245986\n"]}, {"name": "stderr", "output_type": "stream", "text": ["\n", "real\t0m15.743s\n", "user\t0m35.126s\n", "sys\t0m0.117s\n"]}], "source": ["%%bash\n", "\n", "time python 003_fibonacci4.py"]}, {"cell_type": "markdown", "id": "61ce0b85", "metadata": {}, "source": ["### 002.002 The Rules of Async IO\n", "\n", "Here\u2019s one example of how async IO cuts down on wait time: given a coroutine makerandom() that keeps producing random integers in the range [0, 10], until one of them exceeds a threshold, you want to let multiple calls of this coroutine not need to wait for each other to complete in succession. You can largely follow the patterns from the two scripts above, with slight changes\n", "\n", "1. `makerandom` \n", "    1. should keep generating `i` until one it's greater than threshold.\n", "    1. if it isn't, it should print f\"{i} too low; retrying.\",\n", "    1. then sleep asynchronously for `i + 1` seconds, \n", "    1. the generate a new one\n", "1. `main`\n", "    1. should run 3 makerandom with idx in range 0 to 2 asynchronously\n", "1. should gather the results\n"]}, {"cell_type": "code", "execution_count": 13, "id": "5b4db5ae", "metadata": {}, "outputs": [{"data": {"text/plain": ["1"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["2"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["3"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}, {"name": "stdout", "output_type": "stream", "text": ["\u001b[36mInitiated makerandom(idx=0, threshold=8).\n", "\u001b[36m4 too low; retrying.\n", "\u001b[91mInitiated makerandom(idx=1, threshold=7).\n", "\u001b[91m4 too low; retrying.\n", "\u001b[35mInitiated makerandom(idx=2, threshold=6).\n", "\u001b[35m0 too low; retrying.\n", "\u001b[35m4 too low; retrying.\n", "\u001b[36m7 too low; retrying.\n", "\u001b[91m4 too low; retrying.\n", "\u001b[35m4 too low; retrying.\n", "\u001b[91m---> Finished: makerandom(1) == 8\u001b[0m\n", "\u001b[35m---> Finished: makerandom(2) == 10\u001b[0m\n", "\u001b[36m7 too low; retrying.\n", "\u001b[36m8 too low; retrying.\n", "\u001b[36m4 too low; retrying.\n", "\u001b[36m7 too low; retrying.\n", "\u001b[36m1 too low; retrying.\n", "\u001b[36m6 too low; retrying.\n", "\u001b[36m---> Finished: makerandom(0) == 9\u001b[0m\n", "\n", "r1: 9, r2: 8, r3: 10\n"]}], "source": ["import asyncio\n", "import random\n", "\n", "# ANSI colors\n", "c = (\n", "    \"\\033[0m\",   # End of color\n", "    \"\\033[36m\",  # Cyan\n", "    \"\\033[91m\",  # Red\n", "    \"\\033[35m\",  # Magenta\n", ")\n", "\n", "# f\"{i} too low; retrying.\"\n", "\n", "# this is needed to make asyncio run inside notebooks, without the\n", "# This event loop is already running RunTimeError\n", "import nest_asyncio\n", "nest_asyncio.apply()\n", "\n", "1\n", "# async def makerandom(idx: int, threshold: int = 6) -> int:\n", "#     threshold = 10 - idx - 1\n", "#     print(c[idx + 1] + f\"Initiated makerandom({idx=}, {threshold=}).\" + c[0])\n", "#     i = random.randint(0, 10)\n", "#     ...\n", "#     print(c[idx + 1] + f\"---> Finished: makerandom({idx}) == {i}\" + c[0])\n", "#     return i\n", "\n", "2\n", "# async def main():\n", "#     ..\n", "#     return res\n", "\n", "3\n", "# random.seed(444)\n", "# r1, r2, r3 = asyncio.run(main())\n", "# print(f\"r1: {r1}, r2: {r2}, r3: {r3}\")\n", "\n", "# solution\n"]}, {"cell_type": "markdown", "id": "139bfb11", "metadata": {}, "source": ["### 002.003 Chaining Coroutines\n", "\n", "A key feature of coroutines is that they can be chained together. (Remember, a coroutine object is awaitable, so another coroutine can await it.) This allows you to break programs into smaller, manageable, recyclable coroutines:\n", "\n", "1. `load` \n", "    1. waits i secs, asynchronously\n", "    1. returns i\n", "1. `fire`\n", "    1. waits i secs, asynchronously\n", "    1. returns i plus the i from the following step as a tuple\n", "1. `chain`\n", "    1. runs load, then feeds result to fire\n", "    1. Up to 3.7 you needed to do `asyncio.get_event_loop().run_until_complete(` but now you can just use...\n", "1. `main`\n", "    1. initiates an instance of `chain` for each arg, concurrently\n", "1. finally\n", "    1. runs all the jobs in `main`\n"]}, {"cell_type": "code", "execution_count": 14, "id": "f4b84ca7", "metadata": {}, "outputs": [{"data": {"text/plain": ["1"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["2"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["3"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["4"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["5"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}, {"name": "stdout", "output_type": "stream", "text": ["loading cannon: (will take 8 seconds)\n", "loading laser: (will take 4 seconds)\n", "loading railgun: (will take 3 seconds)\n", "railgun loaded..\n", "firing railgun: (will take 8 seconds)\n", "laser loaded..\n", "firing laser: (will take 8 seconds)\n", "cannon loaded..\n", "firing cannon: (will take 0 seconds)\n", "cannon fired!\n", "--> Timing for cannon: total 8.00 seconds, partial (8, 0).\n", "railgun fired!\n", "--> Timing for railgun: total 11.00 seconds, partial (3, 8).\n", "laser fired!\n", "--> Timing for laser: total 12.00 seconds, partial (4, 8).\n", "Program finished in 12.00 seconds.\n"]}, {"data": {"text/plain": ["1"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "import asyncio\n", "import random\n", "import time\n", "import sys\n", "\n", "# this is needed to make asyncio run inside notebooks, without the\n", "# This event loop is already running RunTimeError\n", "import nest_asyncio\n", "nest_asyncio.apply()\n", "\n", "1\n", "# async def load(n: str) -> int:\n", "#     i = random.randint(0, 10)\n", "#     print(f\"loading {n}: (will take {i} seconds)\")\n", "#     ...\n", "#     print(f\"{n} loaded..\")\n", "#     ...\n", "\n", "2\n", "# async def fire(n: str, last_i: int) -> (int, int):\n", "#     i = random.randint(0, 10)\n", "#     print(f\"firing {n}: (will take {i} seconds)\")\n", "#     ...\n", "#     print(f\"{n} fired!\")\n", "#     ...\n", "\n", "3\n", "# async def chain(n: str) -> None:\n", "#     start = time.perf_counter()\n", "#     ...\n", "#     ...\n", "#     end = time.perf_counter() - start\n", "#     print(f\"--> Timing for {n}: total {end:0.2f} seconds, partial {p2}.\")\n", "\n", "4\n", "# async def main(*args):\n", "#     ...\n", "\n", "5\n", "# random.seed(1672)\n", "# args = [\"cannon\", \"laser\", \"railgun\"]\n", "# start = time.perf_counter()\n", "# ...\n", "# end = time.perf_counter() - start\n", "# print(f\"Program finished in {end:0.2f} seconds.\")\n", "\n", "# solution\n"]}, {"cell_type": "markdown", "id": "c05aefde", "metadata": {}, "source": ["### 002.004 Using a Queue\n", "\n", "There is an alternative structure that can also work with async IO: a number of producers, which are not associated with each other, add items to a queue. Each producer may add multiple items to the queue at staggered, random, unannounced times. A group of consumers pull items from the queue as they show up, greedily and without waiting for any other signal. One use-case for queues (as is the case here) is for the queue to act as a transmitter for producers and consumers that aren\u2019t otherwise directly chained or associated with each other.\n", "\n", "\n", "1. `produce` pushes a random number of jobs to the queue\n", "    1. Use the itertools method that returns a list of n None's\n", "    1. Add a tuple to the queue: one item is a random job number, the other is a timestamp\n", "1. `consumer` gets the next available job and processes it\n", "    1. Q: we are using `while True`, isn't that going to cause problems?\n", "    1. Get the tuple off the queue\n", "    1. Tell the queue it can tick the job as complete\n", "1. `main` orchestrates the whole thing\n", "    1. create a queue\n", "    1. create and schedule a set with a task for each producer\n", "    1. make sure each of these tasks gets eventually garbage collected\n", "    1. do the same for consumer (use male names)\n", "    1. run all the producers tasks\n", "    1. Q: why only the producers?\n", "    1. wait until all jobs are processed\n", "    1. Q: how do we know we are done?\n", "    1. turn off the consumers\n"]}, {"cell_type": "code", "execution_count": 15, "id": "05780379", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Producer Denise added <Civil engineer, contracting> to queue.\n", "    > Consumer Joshua got element <Civil engineer, contracting> in 0.00024 seconds.\n", "Producer Leslie added <Retail banker> to queue.\n", "    > Consumer Michael got element <Retail banker> in 0.00022 seconds.\n", "Producer Denise added <Jewellery designer> to queue.\n", "    > Consumer Joshua got element <Jewellery designer> in 1.99987 seconds.\n", "Producer Leslie added <Advice worker> to queue.\n", "    > Consumer Michael got element <Advice worker> in 1.00088 seconds.\n", "Producer Leslie added <Town planner> to queue.\n", "Producer Denise added <Ophthalmologist> to queue.\n", "Producer Denise added <Teacher, secondary school> to queue.\n", "    > Consumer Joshua got element <Town planner> in 5.99952 seconds.\n", "    > Consumer Michael got element <Ophthalmologist> in 5.00165 seconds.\n", "Producer Leslie added <Mining engineer> to queue.\n", "    > Consumer Michael got element <Teacher, secondary school> in 9.00262 seconds.\n", "    > Consumer Joshua got element <Mining engineer> in 5.99887 seconds.\n", "Program completed in 30.00508 seconds.\n"]}], "source": ["import asyncio\n", "import itertools as it\n", "import random\n", "import time\n", "\n", "# this is needed to make asyncio run inside notebooks, without the\n", "# This event loop is already running RunTimeError\n", "import nest_asyncio\n", "nest_asyncio.apply()\n", "\n", "# async def create_job(size: int = 5) -> str:\n", "#     return fake.job()\n", "\n", "# async def rand_sleep() -> None:\n", "#     i = random.randint(0, 10)\n", "#     await asyncio.sleep(i)\n", "\n", "# async def produce(name: str, q: asyncio.Queue) -> None:\n", "#     n = random.randint(0, 10)\n", "#     for _ in ...\n", "#         await rand_sleep()\n", "#         i = await create_job()\n", "#         t = time.perf_counter()\n", "#         ...\n", "#         print(f\"Producer {name} added <{i}> to queue.\")\n", "\n", "# async def consume(name: int, q: asyncio.Queue) -> None:\n", "#     while True:\n", "#         await rand_sleep()\n", "#         ...\n", "#         now = time.perf_counter()\n", "#         print(f\"Consumer {name} got element <{i}>\"\n", "#               f\" in {now-t:0.5f} seconds.\")\n", "#         ...\n", "\n", "# async def main(nprod: int, ncon: int):\n", "#     q = ...\n", "#     producers = set()\n", "#     for _ in range(nprod):\n", "#         task = ...produce(fake.first_name_female(), q)\n", "#         producers.add(task)\n", "#         ...\n", "#     consumers = set()\n", "#     for _ in range(ncon):\n", "#         task = ...\n", "#         consumers.add(task)\n", "#         ...\n", "#     ...\n", "#     ...\n", "#     for c in consumers:\n", "#         ...\n", "\n", "\n", "# random.seed(444)\n", "# start = time.perf_counter()\n", "# asyncio.run(main(nprod=5, ncon=2))\n", "# elapsed = time.perf_counter() - start\n", "# print(f\"Program completed in {elapsed:0.5f} seconds.\")\n", "\n", "\n", "# solution\n"]}, {"cell_type": "markdown", "id": "b82df488", "metadata": {}, "source": ["### 002.005 Async IO\u2019s Roots in Generators\n", "\n", "The await keyword behaves similarly, marking a break point at which the coroutine suspends itself and lets other coroutines work. \u201cSuspended,\u201d in this case, means a coroutine that has temporarily ceded control but not totally exited or finished. Keep in mind that yield, and by extension yield from and await, mark a break point in a generator\u2019s execution.\n", "\n", "1. `endless` is a generator that each time next is called on it returns one of 9,8,7,6,9...\n", "    1. Import the relevant package\n", "2. use `for ... in ` to print a few iterations of endless\n", "3. print 3 more iterations of e, hard coded"]}, {"cell_type": "code", "execution_count": 16, "id": "dd258f0b", "metadata": {}, "outputs": [{"data": {"text/plain": ["1"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["2"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["3"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["1"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["2"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}, {"name": "stdout", "output_type": "stream", "text": ["09/09 08/17 07/24 06/30 09/39 08/47 \n", "discarding 7\n"]}, {"data": {"text/plain": ["3"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["(6, 9, 8)"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["# this is needed to make asyncio run inside notebooks, without the\n", "# This event loop is already running RunTimeError\n", "import nest_asyncio\n", "nest_asyncio.apply()\n", "\n", "1\n", "# from ...\n", "\n", "# def endless():\n", "#     ...\n", "\n", "# e = endless()\n", "\n", "2\n", "# total = 0\n", "# for i in e:\n", "#     if total < 40:\n", "#         total += i\n", "#         print(f\"{i:02d}/{total:02d}\", end=\" \")\n", "#     else:\n", "#         print()\n", "#         print(f\"discarding {i}\")\n", "#         break\n", "\n", "3\n", "# ...\n", "\n", "# solution\n"]}, {"cell_type": "markdown", "id": "ad2ca90b", "metadata": {}, "source": ["### 002.006 asynchronous generator\n", "\n", "asynchronous iterators and asynchronous generators are not designed to concurrently map some function over a sequence or iterator. They\u2019re merely designed to let the enclosing coroutine allow other tasks to take their turn. The async for and async with statements are only needed to the extent that using plain for or with would \u201cbreak\u201d the nature of await in the coroutine. This distinction between asynchronicity and concurrency is a key one to grasp.\n", "\n", "1. `mygen` is an async generator\n", "    1. It yields a sequence of powers of 2 up to 10\n", "    1. IT prints a separator (`.` for example at each iteration)\n", "    1. In between each yield there is a 0.2 sec async pause\n", "1. `main` is a a wrapper for async iterator and comprehension\n", "    1. `g` uses a list comprehension to put all the items generated by mygen in a list\n", "    1. `f` uses for loop to put all the items generated by mygen in a list, but only if i is not 3 or 5\n", "    1. Both are returned as a tuple\n", "1. Get the tuples and print them out"]}, {"cell_type": "code", "execution_count": 17, "id": "efff1338", "metadata": {}, "outputs": [{"data": {"text/plain": ["3"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["1"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["2"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["3"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}, {"name": "stdout", "output_type": "stream", "text": ["\n", ". . . . . . . . . . \n", "+ + + + + + + + + + "]}, {"data": {"text/plain": ["[1, 2, 4, 8, 16, 32, 64, 128, 256, 512]"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["[1, 2, 16, 32, 256, 512]"]}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": ["# this is needed to make asyncio run inside notebooks, without the\n", "# This event loop is already running RunTimeError\n", "import nest_asyncio\n", "nest_asyncio.apply()\n", "\n", "import concurrent.futures\n", "import time\n", "\n", "\n", "# 1\n", "# async def mygen(sep:str, up_to: int = 10):\n", "#     print()\n", "#     i = 0\n", "#     for i in range(up_to):\n", "#         print(sep, end=\" \")\n", "#         ...\n", "\n", "# 2\n", "# async def main():\n", "#     g = ...\n", "\n", "#     f = []\n", "#     async for j in mygen(\"+\"):\n", "#         if j // 3 % 5:\n", "#             continue\n", "#         f.append(j)\n", "#     return g, f\n", "\n", "3\n", "# g, f =\n", "\n", "# g\n", "# f\n", "\n", "# solution\n"]}, {"cell_type": "markdown", "id": "b9cfba94", "metadata": {}, "source": ["### 002.007 Async web scraper\n", "\n", "n this section, you\u2019ll build a web-scraping URL collector, areq.py, using aiohttp, a blazingly fast async HTTP client/server framework. (We just need the client part.) Such a tool could be used to map connections between a cluster of sites, with the links forming a directed graph.\n", "\n", "1. `fetch_html` sends a get request to a url and returns the HTML content\n", "    1. Use the appropriate method to send an async get request (passing kwargs)\n", "    1. make the response handle any >= 400 request by raising\n", "    1. get the source code (HTML but it will work for .txt files too in fact)\n", "1. `parse` returns the links found in the source\n", "    1. catch all the aiohttp errors and print them\n", "    1. For each link, try and create an absolute link by joining them to the page's url (if they are relative) or not if not needed\n", "    1. Q: Why does it work?\n", "1. `write_one` uses  aiofiles to open files asynchronousloy and write a line at the time\n", "1. `bulk_crawl_and_write` creates a task per url"]}, {"cell_type": "code", "execution_count": 18, "id": "3c11a6c3", "metadata": {}, "outputs": [{"data": {"text/plain": ["1"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["2"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["3"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["4"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["5"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}, {"data": {"text/plain": ["22"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}, {"name": "stdout", "output_type": "stream", "text": ["Got response [200] for URL: https://1.1.1.1/\n", "Found 13 links for https://1.1.1.1/\n", "Wrote results for source URL: https://1.1.1.1/\n", "Got response [200] for URL: https://regex101.com/\n", "Got response [200] for URL: https://www.ietf.org/rfc/rfc2616.txt\n", "Found 0 links for https://www.ietf.org/rfc/rfc2616.txt\n", "Found 14 links for https://regex101.com/\n", "Wrote results for source URL: https://regex101.com/\n", "aioHTTP error: 404, message='Not Found', url=URL('https://docs.python.org/3/this-url-will-404.html')\n", "Got response [200] for URL: https://www.mediamatters.org/\n", "Got response [200] for URL: https://www.politico.com/tipsheets/morning-money\n", "Found 119 links for https://www.politico.com/tipsheets/morning-money\n", "Found 6 links for https://www.mediamatters.org/\n", "Wrote results for source URL: https://www.mediamatters.org/\n", "Wrote results for source URL: https://www.politico.com/tipsheets/morning-money\n", "Got response [200] for URL: https://www.bloomberg.com/markets/economics\n", "Found 0 links for https://www.bloomberg.com/markets/economics\n", "aioHTTP error: 404, message='Not Found', url=URL('https://archive.nytimes.com/www.nytimes.com/guides/')\n"]}], "source": ["# this is needed to make asyncio run inside notebooks, without the\n", "# This event loop is already running RunTimeError\n", "import nest_asyncio\n", "nest_asyncio.apply()\n", "\n", "import aiofiles\n", "import aiohttp\n", "import re\n", "import urllib\n", "from aiohttp import ClientSession\n", "from pathlib import Path\n", "from typing import IO\n", "\n", "outpath = Path(\"_002_python_real_python_urls.txt\")\n", "urls = [\n", "    \"https://regex101.com/\",\n", "    \"https://docs.python.org/3/this-url-will-404.html\",\n", "    \"https://www.nytimes.com/guides/\",\n", "    \"https://www.mediamatters.org/\",\n", "    \"https://1.1.1.1/\",\n", "    \"https://www.politico.com/tipsheets/morning-money\",\n", "    \"https://www.bloomberg.com/markets/economics\",\n", "    \"https://www.ietf.org/rfc/rfc2616.txt\"\n", "]\n", "\n", "HREF_RE = re.compile(r'href=\"(http.*?)\"')\n", "\n", "# 1\n", "# async def fetch_html(url: str, session: ClientSession, **kwargs) -> str:\n", "#     \"\"\"GET request wrapper to fetch page HTML.\"\"\"\n", "\n", "#     resp = ...\n", "#     ...\n", "#     print(\"Got response [%s] for URL: %s\" % (resp.status, url))\n", "#     html = ...\n", "#     return html\n", "\n", "# 2\n", "# async def parse(url: str, session: ClientSession, **kwargs) -> set:\n", "#     \"\"\"Find HREFs in the HTML of `url`.\"\"\"\n", "\n", "#     found = set()\n", "#     try:\n", "#         html = await fetch_html(url=url, session=session, **kwargs)\n", "#     except (\n", "#         ...,\n", "#         ...,\n", "#     ) as e:\n", "#         print(\"aioHTTP error: %s\" % e)\n", "#         return found\n", "#     except Exception as e:\n", "#         print(\"non aioHTTP error: %s\" % e)\n", "#         return found\n", "#     else:\n", "#         for link in HREF_RE.findall(html):\n", "#             try:\n", "#                 # Q: Why does it work?\n", "#                 abslink = ...\n", "#             except (urllib.error.URLError, ValueError):\n", "#                 print(\"Error parsing URL: %s\" % link)\n", "#                 pass\n", "#             else:\n", "#                 found.add(abslink)\n", "#         print(\"Found %d links for %s\" % ( len(found), url))\n", "#         return found\n", "\n", "# 3\n", "# async def write_one(file: IO, url: str, **kwargs) -> None:\n", "#     \"\"\"Write the found HREFs from `url` to `file`.\"\"\"\n", "#     res = await parse(url=url, **kwargs)\n", "#     if not res:\n", "#         return None\n", "#     ...:\n", "#         for p in res:\n", "#             ...write(f\"{url}\\t{p}\\n\")\n", "#         print(\"Wrote results for source URL: %s\" % url)\n", "\n", "# 4\n", "# async def bulk_crawl_and_write(file: IO, urls: set, **kwargs) -> None:\n", "#     async with ClientSession() as session:\n", "#         tasks = []\n", "#         for url in urls:\n", "#             ...\n", "#         await asyncio.gather(*tasks)\n", "\n", "# 5\n", "# with open(outpath, \"w\") as outfile:\n", "#     outfile.write(\"source_url\\tparsed_url\\n\")\n", "# asyncio.run(bulk_crawl_and_write(file=outpath, urls=urls))\n", "\n", "\n", "# solution\n"]}, {"cell_type": "code", "execution_count": 19, "id": "265bdb9b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["source_url\tparsed_url\n", "https://1.1.1.1/\thttps://cloudflare.com\n", "https://1.1.1.1/\thttps://1.1.1.1\n", "https://1.1.1.1/\thttps://pkg.cloudflareclient.com/\n", "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/linux/\n", "https://1.1.1.1/\thttps://www.cloudflare.com/careers/departments/\n", "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/macOS/\n", "https://1.1.1.1/\thttps://1111-releases.cloudflareclient.com/windows/Cloudflare_WARP_Release-x64.msi\n", "https://1.1.1.1/\thttps://play.google.com/store/apps/details?id=com.cloudflare.onedotonedotonedotone\n", "https://1.1.1.1/\thttps://developers.cloudflare.com/warpclient/setting-up/windows/\n", "https://1.1.1.1/\thttps://blog.cloudflare.com/warp-for-desktop\n", "https://1.1.1.1/\thttps://itunes.apple.com/us/app/1-1-1-1-faster-internet/id1423538627\n", "https://1.1.1.1/\thttps://twitter.com/intent/tweet?text=ISPs%20spy%20on%20your%20Internet%20traffic%20and%20sell%20the%20data.%20I%27m%20using%201.1.1.1%20with%20WARP%2C%20a%20free%20app%20which%20makes%20the%20Internet%20on%20my%20phone%20faster%20and%20more%20private.%20You%20should%20get%20the%20app%20too%3A%20https%3A//one.one.one.one\n", "https://1.1.1.1/\thttps://1111-releases.cloudflareclient.com/mac/Cloudflare_WARP.zip\n", "https://regex101.com/\thttps://web.libera.chat/?nick=re101-ibis-?&amp;chan=#regex\n", "https://regex101.com/\thttps://fonts.googleapis.com\n", "https://regex101.com/\thttps://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;1,400&family=Source+Code+Pro:wght@400;500;700&display=swap\n", "https://regex101.com/\thttps://regex101.com\n", "https://regex101.com/\thttps://discord.gg/wUA6F6YqSs\n", "https://regex101.com/\thttps://github.com/sponsors/firasdib\n", "https://regex101.com/\thttps://fonts.gstatic.com\n", "https://regex101.com/\thttps://twitter.com/regex101\n", "https://regex101.com/\thttp://browsehappy.com/\n", "https://regex101.com/\thttps://www.paypal.com/donate/?hosted_button_id=83QZGPDJEX4MN\n", "https://regex101.com/\thttps://turnonjs.com\n", "https://regex101.com/\thttps://github.com/firasdib/Regex101/issues\n", "https://regex101.com/\thttp://whatismarkdown.com/\n", "https://regex101.com/\thttps://github.com/firasdib/Regex101/wiki\n", "https://www.mediamatters.org/\thttps://www.instagram.com/mediamattersforamerica/\n", "https://www.mediamatters.org/\thttps://twitter.com/mmfa\n", "https://www.mediamatters.org/\thttps://www.mediamatters.org/\n", "https://www.mediamatters.org/\thttps://www.mediamatters.org\n", "https://www.mediamatters.org/\thttps://www.facebook.com/Mediamatters/\n", "https://www.mediamatters.org/\thttps://www.youtube.com/channel/UC_70iWZ6ym2cglS_kv5YfmA\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/2023/11/30/realtors-face-reckoning-in-probe-by-bidens-doj-00129363\n", "https://www.politico.com/tipsheets/morning-money\thttps://twitter.com/intent/tweet?url=https://politi.co/3uAJ8b1&amp;text=Volcker is still in the building at the Fed&amp;via=politico\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/cannabis\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/california\n", "https://www.politico.com/tipsheets/morning-money\thttps://ad.doubleclick.net/ddm/clk/573442443;382503409;f\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/careers\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/energy-and-environment\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/faq\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/morning-money\n", "https://www.politico.com/tipsheets/morning-money\thttp://www.powerjobs.com/\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/series/states/the-fifty\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/capital-city\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/altitude\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/playbook\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/terms-of-service\n", "https://www.politico.com/tipsheets/morning-money\thttps://womenruleleadingwithpurpose.splashthat.com/TopicalNewsletter\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/morning-money/2023/11/28/patrick-mchenrys-crypto-scramble-00128818\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/magazine\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/labor\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/pro-canada\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/new-york\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.eu/power-play-podcast/?cid=mkt_powerplay_NL\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/defense\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/transportation\n", "https://www.politico.com/tipsheets/morning-money\thttps://oversight.house.gov/wp-content/uploads/2023/11/FDIC-Sexual-Harassment-and-Discrimination-11202023.pdf\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.nytimes.com/2023/12/01/business/energy-environment/us-oil-production-record-climate.html\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/live-events/previous\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/payment\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/rich-lowry\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.wsj.com/us-news/fdic-toxic-atmosphere-strip-clubs-lewd-photos-boozy-hotel-12c89da7\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/education\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/white-house\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/interactives/2023/republican-candidates-2024-gop-presidential-hopefuls-list/\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/2024-elections\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/2023/12/04/trump-revenge-gop-00129418\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/florida\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/morning-money/2023/12/01/china-hawks-plot-mchenry-end-run-00129511\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.eenews.net/\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/do-not-sell\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/settings\n", "https://www.politico.com/tipsheets/morning-money\thttps://ad.doubleclick.net/ddm/clk/573442446;382503412;c\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.facebook.com/politico/\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/morning-money/2023/12/04/volcker-is-still-in-the-building-at-the-fed-00129850\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/sustainability\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/playbook-pm\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/dims4/default/27ede68/2147483647/legacy_thumbnail/72x72/quality/90/?url=https%3A%2F%2Fstatic.politico.com%2Fcf%2F05%2Fee684a274496b04fa20ba2978da1%2Fpolitico.png\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/2023/12/04/trudeau-plays-the-trump-card-00129689\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/politics\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/cartoon-carousel\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/privacy\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/2023/12/04/senate-dems-border-talks-are-dead-senate-republicans-theres-still-a-pulse-00129900\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/sitemap\n", "https://www.politico.com/tipsheets/morning-money\thttps://twitter.com/politico\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/write-for-us\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.reuters.com/legal/ex-wells-fargo-ceo-sues-bank-34-million-withheld-pay-stock-2023-12-02/\n", "https://www.politico.com/tipsheets/morning-money\thttps://subscriber.politicopro.com/article/2023/12/house-gop-eyes-china-investment-deal-early-next-year-00129612\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/feedback\n", "https://www.politico.com/tipsheets/morning-money\thttps://policies.google.com/terms\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/health-care\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/huddle/\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/_login?base=https%3A%2F%2Fwww.politico.com&amp;redirect=%2F_login&amp;logout=%2F_logout&amp;lRedirect=true&amp;sRedirect=%2Fsettings&amp;js=false\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/advertising\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/womenrule\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.instagram.com/politico/\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/technology\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/live-events/upcoming\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/west-wing-playbook\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/dims4/default/c73c7f7/2147483647/legacy_thumbnail/57x57/quality/90/?url=https%3A%2F%2Fstatic.politico.com%2Fcf%2F05%2Fee684a274496b04fa20ba2978da1%2Fpolitico.png\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/immigration\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/gallery\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/live-updates/congress\n", "https://www.politico.com/tipsheets/morning-money\thttps://ad.doubleclick.net/ddm/clk/573442440;382671864;n\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/dims4/default/59ee5a3/2147483647/legacy_thumbnail/114x114/quality/90/?url=https%3A%2F%2Fstatic.politico.com%2Fcf%2F05%2Fee684a274496b04fa20ba2978da1%2Fpolitico.png\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/video\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/corrections\n", "https://www.politico.com/tipsheets/morning-money\thttps://policies.google.com/privacy\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/cybersecurity\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/new-jersey\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/politico-nightly\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/podcasts\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com//_logout?base=https%3A%2F%2Fwww.politico.com&amp;redirect=%2F_logout&amp;js=false\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.eu/uk\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/morning-money/archive\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/column-on-politics\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/rss\n", "https://www.politico.com/tipsheets/morning-money\thttp://edition.pagesuite-professional.co.uk/Launch.aspx?bypass=true&amp;PBID=74262970-aa07-44b3-80c8-21fa8a8ac376\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/subscribe/breaking-news-alerts\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/about-us\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/2023/12/04/biden-response-red-sea-attacks-00130018\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/privacy-policy\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/morning-money/2023/11/30/nikki-haley-gets-the-dimon-treatment-00129247\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.eu\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/morning-money/2023/11/29/why-a-soft-landing-might-not-solve-bidens-polling-problem-00129003\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/staff/victoria-guida\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/politico-weekend\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/legal\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politicopro.com/\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.facebook.com/sharer/sharer.php?u=https://politi.co/3uAJ8b1\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/finance\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters/the-recast\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/trade\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politicopro.com/pro-reporting/?cid=promkt_20q1_corenews_act_money\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/newsletters\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/2023/12/04/divers-japan-osprey-crash-air-foce-00129875\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/press/about\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/agriculture\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/tag/column-tomorrow\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/fourth-estate\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.wsj.com/finance/regulation/fdic-faces-internal-reckoning-over-toxic-culture-allegations-ca28e2bf\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/dims4/default/bd69088/2147483647/legacy_thumbnail/144x144/quality/90/?url=https%3A%2F%2Fstatic.politico.com%2Fcf%2F05%2Fee684a274496b04fa20ba2978da1%2Fpolitico.png\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/matt-wuerker\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/elections\n", "https://www.politico.com/tipsheets/morning-money\thttps://static.politico.com/resource/0000017e-7fd1-d4e5-adfe-7ff9f1280001/styleguide/assets/css/style-core.js.b3d317efb1e60e48d6ec82b01927c270.gz.css\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/2023/11/17/house-panel-launches-investigation-into-fdic-misconduct-00127822\n", "https://www.politico.com/tipsheets/morning-money\thttps://static.politico.com/cf/05/ee684a274496b04fa20ba2978da1/politico.png\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/subscriptions\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/rss/politicopicks.xml\n", "https://www.politico.com/tipsheets/morning-money\thttps://www.politico.com/news/foreign-affairs\n"]}], "source": ["%%bash\n", "cat _002_python_real_python_urls.txt"]}], "metadata": {"kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.6"}, "vscode": {"interpreter": {"hash": "7daeb9a356073df578df6d7584369b7908e732a3e4cb2289ee7d810fc6635fc0"}}}, "nbformat": 4, "nbformat_minor": 5}